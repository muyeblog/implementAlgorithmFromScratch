{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientBoostingInPythonFromScratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbLYJoRiIHo8UkZCi5l6Mc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muyeblog/implementAlgorithmFromScratch/blob/master/GradientBoostingInPythonFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 本文中涉及到的回归树一些公式，与统计学习方法中提升树一节中的公式存在不同的情况，我认为可以以统计学习方法中的提升树为主，但是文中回归树的代码还是可以参考学习的。\n",
        "\n",
        "其中的代码 git地址为：\n",
        "https://gist.github.com/Eligijus112"
      ],
      "metadata": {
        "id": "28bpriVjQaPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting in Python from Scratch\n",
        "\n",
        "https://towardsdatascience.com/gradient-boosting-in-python-from-scratch-788d1cf1ca7"
      ],
      "metadata": {
        "id": "__Cvu2Jmtysg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aim of this article is to explain every bit of the popular and oftentimes **mysterious gradient boosting algorithm** using Python code and visualizations. Gradient boosting is the key part of such competition-winning algorithms as CAT boost, ADA boost or XGBOOST thus knowing what is boosting, what is the gradient and how the two are linked in creating an algorithm is a must for any modern machine learning practitioner.\n",
        "\n",
        "\n",
        "The implementation and animations(实现和动画) of gradient boosting for regression in Python can be accessed in my repo: https://github.com/Eligijus112/gradient-boosting"
      ],
      "metadata": {
        "id": "BwRlBlM2t76D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://miro.medium.com/max/1400/1*cQ69MSfNojO9i_asf432_A.jpeg)\n",
        "\n",
        "The main  picture  of the article depicts(描绘) the process of evolution(进化的过程) and how, over a long period of time, the beak size of a bird species adapts to its surroundings(鸟类的喙的大小如何在很长一段时间内适应其周围环境).https://en.wikipedia.org/wiki/Darwin%27s_finches\n",
        "\n",
        "Just like animals adapt in various ways given new facts in their habitats(栖息地),(就像动物以各种方式适应栖息地中的新事实一样),so do machine learning algorithms adapt to the data environment we put them in.The main idea behind the gradient boosting algorithm is that the main engine of it is a low accuracy and simple algorithm which learns from its own previous mistake(梯度提升算法背后的主要思想是，它的主要引擎是一个低准确率且简单的算法，它从自己之前的错误中学习)."
      ],
      "metadata": {
        "id": "F3Hrqy-b10GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At every iteration, not just the errors are used to adjust the model, but previous iteration's models get invoked as well. Thus, with every pass over the data, the gradient boosting model gets more complex and complex because in it adds more and more simple models together."
      ],
      "metadata": {
        "id": "uSWxB_bL4ANN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a nutshell(简而言之)，the simplified equation of many gradients boosting algorithms is a recursion(递归):\n",
        "\n",
        "$F_m(x) = F_{m-1}(x) + \\alpha G_m(x)$\n",
        "\n",
        "The current value *m*(think about it as the present) uses the past information (m-1) and gets adjusted by new present evidence(G) with a certain weight.\n",
        "\n",
        "In the article below, we will dive deeper into the nitty-gritty details of gradient boosting(将深入探讨梯度提升的细枝末节) and I hope that after going through all the code and explanations, the reader will see the gradient boosting while sounding intimidating(听起来吓人), is not that complex."
      ],
      "metadata": {
        "id": "PYs71bRF40jY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us imagine we want to have a model to predict how many miles can a car drive based on the car's weight. The data can be accessed from here:\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/auto+mpg\n",
        "\n",
        "\n",
        "The data with all features:\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*uvc-O_fnX5pXCq0Mzpb-9A.png)"
      ],
      "metadata": {
        "id": "N8Sm_mEp6Skl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The relationship in question:\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*oPekoKlRkgLdkT2b3aGGAw.png)\n",
        "mpg ~ weight; Graph by author\n",
        "\n",
        "\n",
        "\n",
        "There is a clear relationship --- the heavier the car, the fewer miles per gallon it can go. Let us try to fit a base learner to the data and see how it performs.\n",
        "\n",
        "Let us start building a gradient boosting machine learning algorithm to model this relationship."
      ],
      "metadata": {
        "id": "bV6584Uf6raZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression gradient boosting algorithm has three very broad machine learning terms in its title:\n",
        "\n",
        "- Regression\n",
        "- Gradient\n",
        "- Boosting\n",
        "\n",
        "It is important to have at least an intuitive(直觉) understanding of the standalone definitions(独立的定义)  before trying to merge them together.\n"
      ],
      "metadata": {
        "id": "iVIAE3kc7VDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression:\n",
        "  Regression in machine learning means finding a relationship $f$ between a continuous variable's $Y$ average value and features $X$.\n",
        "\n",
        "  $E[Y] = f(X)$\n",
        "\n",
        "In regression, the variable we are trying to predict is continuous, that is ,it can have an infinite(无限的) number of values. For example, human weight, the speed at which a person will finish a race in the Olympics, a person's wage(工资), etc.\n",
        "\n",
        "The way in which we are trying to explain the $Y$ variable is using features $X$. For example, we can say that a person's wage (the $Y$ variable) is determined by his or her experience in a workplace, academic achievements, certificate amounts, etc (the $X$ variable).\n",
        "\n"
      ],
      "metadata": {
        "id": "nGWaQs-A769m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The gradients\n",
        "The gradients of a function in mathematics is a vector whose each coordinate is a partial derivative of a given function's argument(数学中函数的梯度是一个向量，其每个坐标都是给定函数参数的偏导数).\n",
        "\n",
        "$\\nabla f(x_1,...,x_p) = [\\frac{\\partial f}{\\partial x_1},...,\\frac{\\partial f}{\\partial x_p}]$\n",
        "\n",
        "Gradient definition\n",
        "\n",
        "The gradient is very widely in popular algorithms used when finding the function argument that minimizes or maximizes the function. It is because of the fact that at any given point $x$ if the function's gradient is negative then the original function is decreasing at the point $x$。 If at point $x$ the gradient is positive, then the function is increasing. This is why a lot of loss functions in machine learning try to be as simple as possible (the fewer arguments the better) and be differentiable(可微的)(enabling the finding of the gradient)(可以找到梯度).\n",
        "\n"
      ],
      "metadata": {
        "id": "4gkdEJe09TLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The term boosting in machine learning means a process of training a set of weak learners to the training data where each weak learner iteratively learns from previous learners' mistakes(机器学习中的提升一词是指在训练数据上训练一组弱学习器的过程，其中每个弱学习器迭代地从先前学习器的错误中学习).\n",
        "\n",
        "A weak learner is a machine learning algorithm that is quick to fit data but has relatively poor performance in terms of accuracy, mean squared error or other metrics(弱学习器是一种机器学习算法，可以快速拟合数据，但在准确性、均方误差或其他指标方面的性能相对较差).\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*Gl4S98dlRJqMh4jR4eDOJg.png)"
      ],
      "metadata": {
        "id": "FsRUQT1j7jZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above schema, each ML model is a weak learner(在上述的方案中，每一个 ML 模型都是一个弱学习器). Each error is calculated with past predictions(每个错误都是根据过去的预测计算的).Each subsequent model tries to fit the previous errors with the original features(每个后续模型都尝试用原始特征拟合先前的错误误差)(just take a leap of faith here and follow along with the article, I will explain this process in detail later)()."
      ],
      "metadata": {
        "id": "7VU9G8j29ba3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final prediction is a weighted sum of all the outputs from the gotten ML models(最终预测获得的 ML 模型是所有输出的加权和，adaboost是弱分类器，通过加权多数表决):\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*UNNud7AEYk63-wCSk95mMA.png)"
      ],
      "metadata": {
        "id": "FKmR72Ut_F80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regression gradient boosting** is an algorithm that combines all there above ideas into one machine learning method.\n",
        "\n",
        "Before diving deeper into how all the three ideas are interlinked(在深入探讨这三个想法是如何关联之前),we need to select a weak base learner for the boosting part. A very popular choice is a *regression decision tree*(回归决策树). To learn more about the regression decision trees check out my article：\n",
        "\n",
        "[Regression Tree in Python From Scratch](https://towardsdatascience.com/regression-tree-in-python-from-scratch-9b7b64c815e3)"
      ],
      "metadata": {
        "id": "E_gKB-T8VrAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick recap(快速回顾):\n",
        "![](https://miro.medium.com/max/1278/1*e_e1-w8AofrHUt2WuJIzig.png)\n",
        "\n",
        "Regression tree schema\n",
        "\n",
        "\n",
        "Each node in a tree has Y and X features saved to it. Additionally, each node has:\n",
        "- Special residuals of the Y mean were substracted from each of the Y values(从每个Y值中减去 Y 平均值的特殊残差).\n",
        "- The mean squared error for the residuals(残差的均方误差).\n",
        "- The best spliting feature and the best split value for further creation of nodes(进一步创建节点的最佳分类特征和最佳分裂值).\n",
        "- All the initial hyperparameter(所有初始超参数).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J-VR_1T-XD3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Python implementaion of a regression tree:"
      ],
      "metadata": {
        "id": "70CLOvG6kKkS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty_NgE5RtrM0"
      },
      "outputs": [],
      "source": [
        "# Data wrangling\n",
        "\n",
        "import pandas as pd\n",
        "# Infinity constant\n",
        "from math import inf\n",
        "\n",
        "\n",
        "class Tree():\n",
        "  \"\"\"\n",
        "  Class to fit a regression tree to the given data\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "      self,\n",
        "      d:pd.DataFrame,\n",
        "      y_var:str, # label 列名\n",
        "      x_vars:list, # 特征列名 list\n",
        "      max_depth:int = 4,\n",
        "      min_sample_leaf:int = 2\n",
        "  ):\n",
        "    \"\"\"\n",
        "    Class to create the regression tree object.\n",
        "\n",
        "    Arguments\n",
        "    ----------\n",
        "    d: pd.DataFrame\n",
        "      The dataframe to create the tree form\n",
        "    y_var: str\n",
        "      The target values\n",
        "    x_vars: dict\n",
        "      The features to use in the tree\n",
        "    max_depth: int\n",
        "      The maximum depth of the tree\n",
        "    min_sample_leaf: int\n",
        "      The minimum number of observations in each of the subtrees after\n",
        "      spliting\n",
        "    \"\"\"\n",
        "    # Saving the names of y variable and x features\n",
        "    self.y_var = y_var # 列名\n",
        "    self.features = x_vars  # 特征列名\n",
        "\n",
        "    # Saving the node data to memory\n",
        "    # the type of d is pandas.core.frame.DataFrame\n",
        "    self.d = d[[y_var] + x_vars]  # convert str type y_var with '[]',then concatenate with list x_vars\n",
        "\n",
        "    # Saving the data to the node\n",
        "    self.Y = d[y_var].values.tolist()\n",
        "\n",
        "    # Saving the number of observations in the node.\n",
        "    self.n = len(d)\n",
        "\n",
        "    # Initiating the depth counter(初始化深度计数器)\n",
        "    self.depth = 0\n",
        "\n",
        "    #Saving the maximum depth of the tree\n",
        "    self.max_depth = max_depth\n",
        "\n",
        "    # Saving the minimum samples in the dataframe after spliting(拆分后的最小样本)\n",
        "    self.min_sample_leaf = min_sample_leaf\n",
        "\n",
        "    # Calculating the mse\n",
        "    self.get_y_mse()\n",
        "\n",
        "    # Infering the best split\n",
        "    self.get_best_split()\n",
        "\n",
        "    # Saving to memory the y mean (prediction of the node)\n",
        "    self.get_y_mean()\n",
        "  \n",
        "  # x:list 表示 x 的建议类型是 list, -> float 表示函数的返回值建议类型为 float\n",
        "  # 说白了就是用来标识参数类型和返回值类型\n",
        "  @staticmethod # 静态方法，可以无需实例化，通过类目直接调用，也可以实例化对象后使用对象进行调用\n",
        "  def get_mean(x:list) -> float: \n",
        "    \"\"\"\n",
        "    Calculates the mean over a list of float elements\n",
        "    \"\"\"\n",
        "    # Initiating the sum counter\n",
        "    _sum = 0\n",
        "\n",
        "    # Infering(推断、测) the length of list\n",
        "    _n = len(x)\n",
        "\n",
        "    if _n == 0:\n",
        "      return inf\n",
        "    \n",
        "    # Iterating through(遍历) the y values\n",
        "    for _x in x:\n",
        "      _sum += _x\n",
        "    \n",
        "    return _sum / _n\n",
        "  \n",
        "  def get_y_mean(self) -> None:\n",
        "    \"\"\"\n",
        "    Saves the current node's mean\n",
        "    \"\"\"\n",
        "    self.y_mean = self.get_mean(self.Y)\n",
        "  \n",
        "  def get_mse(self,x:list) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the mse of a given list by subtracting the mean,\n",
        "    summing and dividing by n\n",
        "    \"\"\"\n",
        "    # Infering the length of  list\n",
        "    _n = len(x)\n",
        "\n",
        "    if _n == 0:\n",
        "      return inf\n",
        "    \n",
        "    # Calculating the mean\n",
        "    _mean = self.get_mean(x)\n",
        "\n",
        "    # Getting the residuals\n",
        "    residuals = [_x - _mean for _x in x]\n",
        "\n",
        "    # Squaring the residuals\n",
        "    residuals = [r**2 for r in residuals]\n",
        "\n",
        "    # Summing the residuals\n",
        "    _r_sum = 0\n",
        "    for r in residuals:\n",
        "      _r_sum += r\n",
        "    \n",
        "    # Returning the mean squared error\n",
        "    return _r_sum / _n\n",
        "  \n",
        "  def get_y_mse(self) -> None:\n",
        "    \"\"\"\n",
        "    Method to calculate the MSE of the current node\n",
        "    \"\"\"\n",
        "    self.mse = self.get_mse(self.Y)\n",
        "  \n",
        "  def get_mse_weighted(self,y_left:list,y_right:list):\n",
        "    \"\"\"\n",
        "    Calculates the weighted mse given two lists\n",
        "    \"\"\"\n",
        "    # Calculates the length of both values\n",
        "    _n_left = len(y_left)\n",
        "    _n_right = len(y_right)\n",
        "    _n_total = _n_left + _n_right\n",
        "\n",
        "    # Calculating  the mse of each sides\n",
        "    _mse_left = self.get_mse(y_left)\n",
        "    _mse_rigth = self.get_mse(y_right)\n",
        "\n",
        "    # Calculating the weighted mse\n",
        "    return (_mse_left * _n_left / _n_total) + (_mse_right * _n_right / _n_total)\n",
        "  \n",
        "  def get_best_spilt(self):\n",
        "    \"\"\"\n",
        "    Method to find the best split among thee features\n",
        "\n",
        "    The logic is to find the feature and the feature value which reduces\n",
        "    the object mse the most\n",
        "    \"\"\"\n",
        "    #  Setting initial values\n",
        "    _best_mse = self.mse\n",
        "    _best_feature = None\n",
        "    _best_feature_value = None\n",
        "\n",
        "    # Creating lists of categorical and numberical features\n",
        "    _cat_features = [ft for ft in self.d.columns if self.d[ft].dtype == 'category']\n",
        "    _num_features = list(set(self.features) - set(_cat_features))\n",
        "\n",
        "    # Going through the categorical features\n",
        "    for _cat_feature in _cat_features:\n",
        "      # Infering the levels of the categorical feature\n",
        "      _levels = self.d[_cat_feature].unique()\n",
        "\n",
        "      for _level in _levels:\n",
        "        # Spliting the data into two parts: one that is equal to the categrical level\n",
        "        # and one that is not\n",
        "        _y_left = self.d.loc[self.d[_cat_feature] == _level, self.y_var].values\n",
        "        _y_right = self.d.loc[self.d[_cat_feature] != _level, self.y_var].values\n",
        "\n",
        "        if len(_y_left) >= self.min_sample_leaf and len(_y_right) >= self.min_sample_leaf:\n",
        "          # Calculating the weighted mse\n",
        "          _mse_w = self.get_mse_weighted(_y_left,_y_right)\n",
        "\n",
        "          # Checking the values\n",
        "          if _mse_w < _best_mse:\n",
        "            _best_mse = _mse_w\n",
        "            _best_feature = _cat_feature\n",
        "            _best_feature_value = str(_level) # Specificaly adding the type for later spliting\n",
        "          \n",
        "    # Going through the numerical features\n",
        "    for _num_feature in _num_features:\n",
        "      # Getting the values\n",
        "      _values = self.d[_num_feature].values\n",
        "\n",
        "      # Getting the unique entries\n",
        "      _values = list(set(_values))\n",
        "\n",
        "      # Sorting the values\n",
        "      _values.sort()\n",
        "\n",
        "\n",
        "      # Getting the rolling average values of the feature\n",
        "      # and spliting the dataset by that value\n",
        "      for i in range(len(_values) - 1):\n",
        "        # Rolling  average\n",
        "        _left = _values[i]\n",
        "        _right = _values[i + 1]\n",
        "        _mean = (_left + _right)/2\n",
        "\n",
        "        # Iterating over the values and calculating the mse\n",
        "        _y_left = self.d.loc[self.d[_num_feature] <=_mean,  self.y_var].values\n",
        "        _y_right = self.d.loc[self.d[_num_feature] >_mean, self.y_var].values\n",
        "\n",
        "        if len(_y_left) >= self.min_sample.leaf and len(_y_right) >= self.min_sample_leaf:\n",
        "          # Getting the weighted mse\n",
        "          _mse_w = self.get_mse_weighted(_y_left,_y_right)\n",
        "\n",
        "          # Checking the \n",
        "          if _mse_w < _best_mse:\n",
        "            _best_mse = _mse_w\n",
        "            _best_feature = _num_feature\n",
        "            _best_feature_value = _mean\n",
        "\n",
        "    # Saving the best splits to object memory\n",
        "    self.best_feature = _best_feature\n",
        "    self.best_feature_value = _best_feature_value\n",
        "  \n",
        "  def fit(self):\n",
        "    \"\"\"\n",
        "    The recurisive method to fit a regression tree and on the data provided\n",
        "    \"\"\"\n",
        "    if self.depth < self.max_depth:\n",
        "      # Spliting the data depending on the found best splits\n",
        "      _best_feature = self.best_feature\n",
        "      _best_feature_value = self.best_feature_value\n",
        "\n",
        "      # Spliting the data for the creation of additional sub tree\n",
        "      _d_left = pd.DataFrame()\n",
        "      _d_right = pd.DataFrame()\n",
        "      if isinstance(_best_feature_value,str): # isinstance函数是判断 对象 _best_feature_value 是不是 str类型, str类型的数据为categorical特征\n",
        "        _d_left = self.d[self.d[_best_feature] == _best_feature_value].copy()\n",
        "        _d_right = self.d[self.d[_best_feature] != _best_feature_value].copy()\n",
        "      else:\n",
        "        _d_left = self.d[self.d[_best_feature] <= _best_feature_value].copy()\n",
        "        _d_right = self.d[self.d[_best_feature] > _best_feature_value].copy()\n",
        "\n",
        "      # Creating the tree instances\n",
        "      _left_tree = Tree(\n",
        "          d = _d_left,\n",
        "          y_var = self.y_var,\n",
        "          x_vars = self.features,\n",
        "          min_sample_leaf = self.min_sample_leaf,\n",
        "          max_depth = self.max_depth\n",
        "      )\n",
        "      _right_tree = Tree(\n",
        "          d = _d_right,\n",
        "          y_var = self.y_var,\n",
        "          x_vars = self.features,\n",
        "          min_sample_leaf = self.min_sample_leaf,\n",
        "          max_depth = self.max_depth\n",
        "      )\n",
        "\n",
        "      # Setting the depths\n",
        "      _left_tree.depth = self.depth + 1\n",
        "      _right_tree.depth = self.depth + 1\n",
        "\n",
        "      # Defining the rules for the left and right subtrees\n",
        "      _left_symbol = '<='\n",
        "      _right_symbol = '>'\n",
        "\n",
        "      if isinstance(_best_feature_value,str):\n",
        "        _left_symbol = '=='\n",
        "        _right_symbol = '!='\n",
        "      \n",
        "\n",
        "      _rule_left = f\"{_best_feature} {_left_symbol} {_best_feature_value}\"\n",
        "      _rule_right = f\"{_best_feature} {_right_symbol} {_best_feature_value}\"\n",
        "\n",
        "      _left_tree.rule = _rule_left\n",
        "      _right_tree.rule = _rule_right\n",
        "\n",
        "      # Saving the pointers in memory\n",
        "      self.left = _left_tree\n",
        "      self.right = _right_tree\n",
        "\n",
        "      # Continuing the recursive process\n",
        "      self.left.fit()\n",
        "      self.right.fit()\n",
        "  \n",
        "  def print_info(self,width=4):\n",
        "    \"\"\"\n",
        "    Method to print the information about the tree\n",
        "    \"\"\"\n",
        "    # Defining the number of spaces\n",
        "    const = int(self.depth * width ** 1.5)\n",
        "    spaces = \"-\" * const\n",
        "\n",
        "    if self.depth == 0:\n",
        "      print(f\"Root (level {self.depth}\")\n",
        "    else:\n",
        "      print(f\"|{spaces} Split rule:{self.rule} (level {self.depth}|\")\n",
        "    print(f\"{' ' * const} | MSE of the node : {round(self.mse,2)}\")\n",
        "    print(f\"{' ' * const} | Count of obervations in node: {self.n}\")\n",
        "    print(f\"{' ' * const} | Precition of node: {round(self.y_mean,3)}\")\n",
        "  \n",
        "  def print_tree(self):\n",
        "    \"\"\"\n",
        "    Prints the whole tree from the current node to the bottom\n",
        "    \"\"\"\n",
        "    self.print_info()\n",
        "\n",
        "    if self.depth < self.max_depth:\n",
        "      self.left.print_tree()\n",
        "      self.right.print_tree()\n",
        "  \n",
        "  def predict(self,x:dict) -> float:\n",
        "    \"\"\"\n",
        "    Returns the predict Y value based on the X values\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    x: dict\n",
        "      Dictionary of the structure:\n",
        "      {\n",
        "        \"feature_name\": value,\n",
        "      }\n",
        "    Returns\n",
        "    -------\n",
        "    The mean Y based on the x and fitted\n",
        "    \"\"\"\n",
        "    # Infering the node\n",
        "    _node = self\n",
        "    while _node.depth < self.max_depth:\n",
        "\n",
        "      # Extracting the best split feature and values\n",
        "      _best_feature = _node.best_feature\n",
        "      _best_feature_value = _node.best_feature_value\n",
        "\n",
        "      # Checking if the feature is categorical or numerical\n",
        "      if isinstance(_best_feature_value, str):\n",
        "        if x[_best_feature] == _best_feature_value: # categorical feature\n",
        "          _node = _node.left\n",
        "        else:\n",
        "          _node = _node.right\n",
        "      else: # numerical feature\n",
        "        if x[_best_feature] <= _best_feature_value:\n",
        "          _node = _node.left\n",
        "        else:\n",
        "          _node = _node.right\n",
        "    \n",
        "    # Returning the prediction\n",
        "    return _node.y_mean\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "d = pd.DataFrame\n",
        "x_vars = ['name','num']\n",
        "y_var = 'price'\n",
        "type(x_vars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRttTqSYzUqy",
        "outputId": "0b2913b9-59a1-4440-e5cb-b8f2b7292ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'name':['苹果','梨','草莓'],\n",
        "       'num':[3,2,5],\n",
        "       'price':[10,9,8]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akz52zEuK5ph",
        "outputId": "f18b9bfb-6eed-42ab-f24e-ab44e0e61fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  name  num  price\n",
            "0   苹果    3     10\n",
            "1    梨    2      9\n",
            "2   草莓    5      8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[y_var]+x_vars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDf4fQeYK87-",
        "outputId": "5dd3880d-7146-41c4-b59f-2345b2513cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['price', 'name', 'num']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_var:list,y_var:str\n",
        "# z=x_vars + y_var # can only concatenate list (not \"str\") to list\n",
        "# z = y_var + x_vars # can only concatenate str (not \"list\") to str\n",
        "z  = [y_var] + x_vars\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ-XfoQ9MxW-",
        "outputId": "31cceaf8-1beb-4007-c895-49c96901555c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['price', 'name', 'num']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['price', 'name', 'num']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "wJppP4Gn3H5K",
        "outputId": "da93417d-c7cf-4eca-ca38-87ef05e3155e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   price name  num\n",
              "0     10   苹果    3\n",
              "1      9    梨    2\n",
              "2      8   草莓    5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de317a92-8a82-4a93-9970-e0b84f750090\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>name</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>苹果</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>梨</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>草莓</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de317a92-8a82-4a93-9970-e0b84f750090')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de317a92-8a82-4a93-9970-e0b84f750090 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de317a92-8a82-4a93-9970-e0b84f750090');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[y_var]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55sLr4dt8Ut7",
        "outputId": "d0aa7abd-db10-45ec-d1da-8e2b518f651f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    10\n",
              "1     9\n",
              "2     8\n",
              "Name: price, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[ [y_var] + x_vars ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "-DwrFXsV0Ei7",
        "outputId": "bc9a96df-317d-4a9f-c258-f4c8e0effb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   price name  num\n",
              "0     10   苹果    3\n",
              "1      9    梨    2\n",
              "2      8   草莓    5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05790fac-8184-4e7c-937e-4db5a692e284\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>name</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>苹果</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>梨</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>草莓</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05790fac-8184-4e7c-937e-4db5a692e284')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05790fac-8184-4e7c-937e-4db5a692e284 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05790fac-8184-4e7c-937e-4db5a692e284');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RREUdLbz0G75",
        "outputId": "94ad91e4-a42f-4b94-b17f-fc80a6d8479d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(e.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpAM6CVJ2N0Q",
        "outputId": "94672602-b8d9-4e07-80b2-737165ea9152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [1,2,3,4]\n",
        "print(x)\n",
        "x = [r**2 for r in x]\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM0TooJd2mxX",
        "outputId": "06d86a89-7b06-44ef-88b7-a241237ccd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4]\n",
            "[1, 4, 9, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "C-gaRo0gUQYl",
        "outputId": "e423d367-3f9b-4f1a-c4ed-b6ef4b32ca9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  name  num  price\n",
              "0   苹果    3     10\n",
              "1    梨    2      9\n",
              "2   草莓    5      8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f52c97c6-1dd8-4c2c-af36-0b46427be566\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>num</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>苹果</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>梨</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>草莓</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f52c97c6-1dd8-4c2c-af36-0b46427be566')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f52c97c6-1dd8-4c2c-af36-0b46427be566 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f52c97c6-1dd8-4c2c-af36-0b46427be566');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['num']==3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "LemwpZdnCvED",
        "outputId": "20b3a637-b9df-464e-ff9a-8168eb1ef9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  name  num  price\n",
              "0   苹果    3     10"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-077a0686-0c64-40d0-8468-168685fc4346\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>num</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>苹果</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-077a0686-0c64-40d0-8468-168685fc4346')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-077a0686-0c64-40d0-8468-168685fc4346 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-077a0686-0c64-40d0-8468-168685fc4346');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2**1.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5MFajcLUTEz",
        "outputId": "61bccadc-a71a-42a0-a7e2-9985280769a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8284271247461903"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.sqrt(2**3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXdWpcxZeNnH",
        "outputId": "30fecaa5-eb40-499d-ca7b-ba53f85e68d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8284271247461903"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(' '* 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpXTGYeSeVA_",
        "outputId": "bb64bc79-5ef0-42f6-8233-381484fbd834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{' '}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tp94Ae3mXYD",
        "outputId": "ac290d7f-021b-4066-ea36-0c549d332e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' '}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fit one weak learner to the data, run the below code:"
      ],
      "metadata": {
        "id": "tZIXfJLnv5_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 没有数据集\n",
        "# # Initiating the tree\n",
        "# reg = Tree(d,'mpg',['weight'],max_depth=2)\n",
        "\n",
        "# # Fitting on data\n",
        "# reg.fit()  #Initiating the tree\n",
        "\n",
        "# # Printing out the tree\n",
        "# reg.print_tree()"
      ],
      "metadata": {
        "id": "SOQirafQv4X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results:\n",
        "\n",
        "![](https://miro.medium.com/max/994/1*hvaoHiszcNW_mMIUgHme7w.png)\n",
        "\n",
        "The  tree information;"
      ],
      "metadata": {
        "id": "X0wmjCQwwVz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weak learner suggests first splitting the data at 2764.5 weight point, because at that point, the general mean squared error will diminish the most compared to the original mean squared error in the root node.\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*vL1Du6TeFphEA9vhNTxleg.png)\n",
        "\n",
        "Regression tree predictions;"
      ],
      "metadata": {
        "id": "_vGKd5FRwlFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the predictions above, the regression tree split the data into 4 parts: everything until 2217 weight, then from 2217 to 2764.5, then from 2764.5 to 3657.5 and everything from 3657.5. The predicted values are the mean of the Y variable that falls into that weight category. comparing\n",
        "\n",
        "Additionally, the graph(the tree information graph) shows the regression tree with a maximum depth of 2 is a weak learner. Let's figure out how to combine a bunch of them to create a strong learner."
      ],
      "metadata": {
        "id": "FuB8jorNxQfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From wiki, the full gradient boosting algorithm:\n",
        "![](https://miro.medium.com/max/1400/1*SCP1eySY20B1aclq3FtuzQ.png)\n",
        "\n",
        "https://en.wikipedia.org/wiki/Gradient_boosting\n"
      ],
      "metadata": {
        "id": "GRuFFE_82m67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first glance, the above algorithm looks intimidating(咋一看，上面的算法看起来很吓人).But let us go through it line by line and code our way to a  full solution(逐行浏览并编写完整的解决方案).\n",
        "\n",
        "\n",
        "In the coding solution, let us stick with the same example as before(我们坚持与之前相同的示例) and try to create a prediction for mpg using a cars's weight as an explanation.\n",
        "\n",
        "Thus, our data\n",
        "\n",
        "$(x_i,y_i)_{i=1}^N$\n",
        "\n",
        "is in practise\n",
        "\n",
        "$(weight_i,mpg_i)_{i=1}^{398}$\n",
        "\n",
        "The next very important part is selecting a loss function. A very popular loss function for gradient boosting trees is\n",
        "\n",
        "$L(y,\\hat{y})  = \\frac{1}{2}(y-\\hat{y})^2$\n",
        "\n",
        "It is popular because taking its derivative yields(对它求导产生):\n",
        "\n",
        "$\\frac{\\partial{L(y,\\hat{y})}}{\\partial{\\hat{y}}} = -\\frac{2}{2}(y-\\hat{y}) = \\hat{y} -  y$\n",
        "\n",
        "This will come in very handy when simplifying various formulas ahead in the algorithm(算法中的各种公式会带来很大的方便).\n"
      ],
      "metadata": {
        "id": "ChoRqL5A3-5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The initialization of the algorithm —— step 1 —— with our selected loss function:\n",
        "\n",
        "\n",
        "$\\sum_{i=1}^n L(y_i,\\gamma) = \\sum_{i=1}^N \\frac{1}{2}(y_i - \\gamma)^2 = f(\\gamma)$\n",
        "\n",
        "\n",
        "Now to find the argument that minimizes this function we differentiate in terms of gamma and equal it to 0(现在为了找到最小化这个函数的参数， 我们对$\\gamma$进行求导(微分)，使得导数为 0):\n",
        "\n",
        "$\\partial f(\\gamma) = \\sum_{i=1}^N -\\frac{2}{2}(y_i - \\gamma) = - \\sum_{i=1}^N y_i + N \\gamma = 0$\n",
        "\n",
        "所以 有\n",
        "\n",
        "$\\gamma = \\frac{1}{N} \\sum_{i=1}^N y_i$\n",
        "\n",
        "The right-hand side of the above equation(上边等式的右边) is nothing but the mean of the initial $Y$(只是$Y$初始值的均值).Thus, we always start algorithm with initial predictions being the mean of $Y$(因此，我们总是以 $Y$的均值作为初始预测值来开始算法).\n",
        "\n",
        "$F_0 = \\frac{1}{N} \\sum_{i=0}^N y_i = \\bar{y}$\n",
        "\n",
        "In our practical example(在我们实践的例子中), the mean value of the mpg dependent variable is 23.51(因变量mpg的均值是 23.51).\n",
        "\n"
      ],
      "metadata": {
        "id": "sBdmfYlt-PkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second part of the algorithm is the boosting part where we adjust each iteration using information from the previous iteration.\n",
        "\n",
        "The first part of the second step of the algorithm involves the calculation of the so-called pseudo-residuals(伪残差的计算).The term is quite confusing and may sound more complex than it has to be(这个术语很有迷惑性，听起来比它本身更复杂). I like to call them just residuals(残差) and throughout this text,I will use these terms interchangeably. Let us refer back a couple of seconds before(让我们回顾之前的几个部分) and see that the loss function of our choosing is:\n",
        "\n",
        "$\\frac{\\partial{L(y,\\hat{y})}}{\\partial{\\hat{y}}} = -\\frac{2}{2}(y - \\hat{y}) = (\\hat{y} - y)$\n",
        "> 通过平方差损失函数求导得到\n",
        "\n",
        "When $m=1$, the formula from the algorithm definition is the following:\n",
        "\n",
        "> r 表示残差\n",
        "\n",
        "$r_{i1} = -\\frac{\\partial{L(y_i, F_0(x_i))}}{\\partial{F_0(x_i)}} = y_i - F_0(x_i)$\n",
        "\n",
        "The first iteration's residuals will by calculated by subtracting the mean of y from all individual values of y.\n",
        "\n",
        "\n",
        "![](https://miro.medium.com/max/372/1*r-fI7sIUAfAPMJpgJfbcTQ.png)\n",
        "> The first batch of residuals (r_1); Mean of mpg=23.51\n",
        "\n",
        "\n",
        "From the above part, the term gradient comes up, because we are using the gradient of the loss function in further steps.\n",
        "\n",
        "The second part of the second step of  the algorithm is to fit a  regression tree with the sample feature X but now the Y values are the residuals gotten from the first part. In other words, find a relationship using the regression tree:\n",
        "\n",
        "$h(r_1) = X$\n",
        "\n",
        "The third part of the second step involves quite a lengthy formula(涉及一个相当冗长的公式). Let us expand it:\n",
        "\n",
        "$\\sum_i=1^{N} = L(y_i,F_{m-1}(x_i) + \\gamma h_m(x_i) ) = \\sum_{i=1}^N\\frac{1}{2}(y_i - F_{m-1}(x_i) - \\gamma h_m(x_i))^2 = f(\\gamma)$\n",
        "\n",
        "Optimizing for gamma yields:\n",
        "\n",
        "$\\frac{\\partial f(\\gamma)}{\\partial \\gamma} = \\sum_{i=1}^N ((y_i - F_{m-1}(x_i) - \\gamma h_m(x_i))h_m(x_i))=\\sum_{i=1}^N (yh_m(x_i) - F_{m-1}(x_i)h_m(x_i) - h_m(x_i)^2 \\gamma) = 0$\n",
        "\n",
        "$\\gamma \\sum_{i=1}^N h_m(x_i)^2 = \\sum_{i=1}^N(h_m(x_i)(y_i - F_{m-1}(x_i) ))$ \n",
        "\n",
        "\n",
        "\n",
        "And thus the optimial gamma for iteration m is found using the formula:\n",
        "\n",
        "$\\gamma_m^* = \\frac{\\sum_{i=1}^Nh_m(x_i)(y_i - F_{m-1}(x_i) )}{\\sum_{i=1}^Nh_m(x_i)^2}$\n",
        "\n",
        "The above equation is generic solution for the original algorithm. In his original paper,  https://jerryfriedman.su.domains/ftp/trebst.pdf Jerome H. Friedman proposed that when using decision trees as weak learners, we should use a gamma value not only for each level m but also for each leaf j.\n",
        "\n",
        "$\\gamma_{jm} = argmin_{\\gamma} \\sum_{x_i \\in R_{jm}} L(y_i,F_{m-1}(x_i) + \\gamma)$\n",
        "\n",
        "Suppose that the region (leaf in the regression tree) R has k entries. Then we can solve the optimization problem analytically:\n",
        "\n",
        "$f(\\gamma) = \\sum_{i=1}^k L(y_i,F_{m-1}(x_i) + \\gamma) = \\sum_{i=1}^k\\frac{1}{2}(y_i - F_{m-1}(x_i)-\\gamma)^2 $\n",
        "\n",
        "$\\frac{\\partial f}{\\partial \\gamma} = \\sum_{i=1}^k  (\\gamma + F_{m-1}(x_i) -y_i) = k\\gamma + \\sum_{i=1}^k(F_{m-1}(x_i) -y_i)=0$\n",
        "\n",
        "$\\gamma_{jm}^* = \\frac{1}{k}(y_i - F_{m-1}(x_i)) = \\overline{res_{m-1}}$\n",
        "\n",
        "\n",
        "The above equation finalizes to a very handy property that the optimal gamma value at each iteration m and leaf j is the mean of the residuals that fall into that leaf.\n"
      ],
      "metadata": {
        "id": "_6GMis6mB3dT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fourth part of the second step of the algorithm is just the definition for prediction at step m:\n",
        "\n",
        "$F_{m}(x) = F_{m-1}(x) +  \\alpha \\gamma_{m}h_{m}(x)$\n",
        "\n",
        "The newe term alpha on the right-hand side is a hyperparameter that is defined prior to iteration. It is called the learning rate and controls how much the prediction gets updated at each step.\n",
        "\n",
        "The extension proposed by Friedman is to use the following equation:\n",
        "\n",
        "$F_{m}(x) = F_{m-1}(x) + \\alpha \\sum_{j=1}^J \\gamma_{jm} I_{x\\in{R_j}}$\n",
        "\n",
        "\n",
        "In the python implementation, I will be using  Friedman's approach.\n",
        "\n",
        "We can further simplify Friedman's equation.\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*qKPV7RFycYjPHAikbNaJ4g.png)\n",
        "\n",
        "Weak learner graph; Graph by author"
      ],
      "metadata": {
        "id": "44h_q760AEHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each weak learner predicts the errors of the previous iteration given some set of features. In our example case, the X feature is car weight. At every leaf node, the prediction is the mean residual value that falls into that leaf.\n",
        "\n",
        "Thus, we can simply rewrite the equation to:\n",
        "\n",
        "$F_m(x) = F_{m-1}(x) + \\alpha h_m(x)$\n",
        "\n",
        "Gradient boosting final formula"
      ],
      "metadata": {
        "id": "bSkOJWHIEljB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last and third step of the algorithm is just the definition of the final prediction. If we train for 3 iterations, then the prediction is:\n",
        "\n",
        "$F_3(x) = \\overline{y} + \\alpha(h_1(x) + h_2(x) + h_3(x))$\n",
        "\n",
        "We can see from the right-hand side of the equation is that what we are basically doing with each of the iterations is updating the mean value of y. In a sense, we are combining the weak predictors in such a way that we get the most accurate divergences from the mean for each of the data points. This and the fact that the predicted values are continues let us call above algorithm a regession problem.\n"
      ],
      "metadata": {
        "id": "At7MDL7lpWFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implementation in Python of regression gradient boosting:\n"
      ],
      "metadata": {
        "id": "il5Smn8WDFik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The basic class with the weak learner\n",
        "\n",
        "from regression.tree import tree\n",
        "\n",
        "# Data wrangling"
      ],
      "metadata": {
        "id": "b5VlOscpmjBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data wrangling\n",
        "import pandas as pd\n",
        "\n",
        "#Python infinity \n",
        "from math import inf\n",
        "\n",
        "class RegressionGB():\n",
        "  \"\"\"\n",
        "  Class that implements the regression gradient boosting algorithm\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "     self,\n",
        "     d:pd.DataFrame,\n",
        "     y_var: str,\n",
        "     x_vars: list,\n",
        "     max_depth: int = 4,\n",
        "     min_sample_leaf: int = 2,\n",
        "     learning_rate: float = 0.4,\n",
        "  ):\n",
        "    # Saving the names of y variable and X features\n",
        "    self.y_var = y_var\n",
        "    self.features = x_vars\n",
        "\n",
        "    # Saving the node data to memory\n",
        "    self.d = d[[y_var] + x_vars].copy()\n",
        "\n",
        "    # Saving the data to the node\n",
        "    self.Y = d[y_var].values.tolist()\n",
        "\n",
        "    # Saving the number of observation in data\n",
        "    self.n = len(d)\n",
        "\n",
        "    # Saving the tree hyper parameters\n",
        "    self.max_depth = max_depth\n",
        "    self.min_sample_leaf = min_sample_leaf\n",
        "\n",
        "    # Saving the learning rate\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    # Weak learner list\n",
        "    self.weak_learners = []\n",
        "\n",
        "    # Setting the current iteration m to 0\n",
        "    self.cur_m = 0\n",
        "\n",
        "    # Saving the mean of y\n",
        "    self.y_mean = self.get_mean(self.Y)\n",
        "\n",
        "    # Saving the y_mean as the most recent prediction\n",
        "    self._predictions = [self.y_mean] * self.n\n",
        "  \n",
        "  @staticmethod\n",
        "  def get_mean(x:list) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the mean over a list of float elements\n",
        "    \"\"\"\n",
        "    # Initiating the sum counter\n",
        "    _sum = 0\n",
        "\n",
        "    # Infering the length of list\n",
        "    _n = len(x)\n",
        "\n",
        "    if _n == 0:\n",
        "      return inf\n",
        "    \n",
        "    # Iterating through the y values\n",
        "    for _x in x:\n",
        "      _sum += x\n",
        "    \n",
        "    # Returning the mean \n",
        "    return _sum / _n\n",
        "  \n",
        "  def fit(\n",
        "      self,\n",
        "      m: int = 10\n",
        "  ):\n",
        "    \"\"\"\n",
        "    Applies the iterative algorithm\n",
        "    \"\"\"\n",
        "    # Converting the X to suitable inputs\n",
        "    _inputs = self.d[self.features].to_dict('records') # [{'column_name1':'value1','column_name2':'value2',...,},{}]\n",
        "\n",
        "    # Saving the gamma list to memory\n",
        "    self.gamma = []\n",
        "\n",
        "    # Iterating over the number of estimators\n",
        "    for _ in range(self.cur_m, self.cur_m + m):\n",
        "      # Calculating the residuals\n",
        "      _residuals = [self.Y[i] - self._predictions[i] for i in range(self.n)]\n",
        "\n",
        "      # Saving the current iterations residuals to the original dataframe\n",
        "      _r_name = f\"residuals\"\n",
        "      self.d[_r_name] = _residuals\n",
        "\n",
        "      # Creating a weak learner\n",
        "      _weak_learner = Tree(\n",
        "          d = self.d.copy(),\n",
        "          y_var = _r_name,\n",
        "          x_vars = self.features,\n",
        "          max_depth = self.max_depth,\n",
        "          min_sample_leaf = self.min_sample_leaf,\n",
        "      )\n",
        "\n",
        "      # Growing the tree on the residuals\n",
        "      _weak_learner.fit()\n",
        "\n",
        "      # Appending the weak learner predictions\n",
        "      _predictions_wl = [_weak_learner.predict(_x) for _x in inputs]\n",
        "\n",
        "      # Updating the current precitions\n",
        "      self._predictions = [self._predictions[i] + self.learning_rate * _predictions_wl[i] for i in range(self.n)]\n",
        "    \n",
        "    #  Incrementing the current iteration\n",
        "    self.cur_m += m\n",
        "  \n",
        "  def predict(self, x:dict) -> float:\n",
        "    \"\"\"\n",
        "    Given the dictionary, predict the value of the y variable\n",
        "    \"\"\"\n",
        "    # Starting from the mean\n",
        "    yhat = self.y_mean\n",
        "\n",
        "    for _m in range(self.cur_m):\n",
        "      yhat += self.learning_rate * self.weak_learners[_m].predict(x)\n",
        "    \n",
        "    return yhat\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ntrz18-hDho6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['price', 'name', 'num']].to_dict('records')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se9xv3dhJklq",
        "outputId": "2d8c1f86-eee1-45b7-dafd-8f79368e1e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': '苹果', 'num': 3, 'price': 10},\n",
              " {'name': '梨', 'num': 2, 'price': 9},\n",
              " {'name': '草莓', 'num': 5, 'price': 8}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df[['price', 'name', 'num']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx38DqoTJlbX",
        "outputId": "72191da3-c0b1-43b0-968e-7645df15f6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code for producing the visiualing of gradient boosting training can be found here:\n",
        "\n",
        "https://github.com/Eligijus112/gradient-boosting/blob/master/regression/boosting.py\n"
      ],
      "metadata": {
        "id": "AxuXy3sWOzHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6cA1m3iqJsMa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}