{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gbdt_numba.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3P0/ZuqKbzaLNoQGW7mNB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muyeblog/implementAlgorithmFromScratch/blob/master/gbdt_numba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZHy4xJAzl6Ed"
      },
      "outputs": [],
      "source": [
        "# 摘自：https://github.com/drop-out/Machine-Learning-From-Scratch/blob/master/gbdt_numba.py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABCMeta,abstractmethod\n",
        "import numpy as np\n",
        "from numba import jit"
      ],
      "metadata": {
        "id": "MBxCUn8tl9fI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 注解 @jit:\n",
        "# 它能克服上述效率问题，极大提升代码执行速度，\n",
        "# 同时保留Python语言的易用性。 使用JIT技术时，\n",
        "# JIT编译器将Python源代码编译成机器直接可以执行的机器语言，\n",
        "# 并可以直接在CPU等硬件上运行。\n",
        "@jit\n",
        "def leaf_score(g,h,reg_lambda):\n",
        "  '''\n",
        "  Given the gradient and hessian of a tree leaf,\n",
        "  return the prediction(score) at this leaf.\n",
        "  The score is -G/(H+λ).\n",
        "  '''\n",
        "  return -np.sum(g)/(np.sum(h) + reg_lambda)\n",
        "\n",
        "# 第 t 棵树的损失函数\n",
        "@jit\n",
        "def leaf_loss(g,h,reg_lambda):\n",
        "  '''\n",
        "  Given the gradient and hessian of a tree leaf,\n",
        "  return the minimized loss at this leaf.\n",
        "  The minimized loss is -0.5*G^2/(H+λ).\n",
        "  '''\n",
        "  return  -0.5*np.square(np.sum(g))/(np.sum(h) + reg_lambda)\n",
        "\n",
        "@jit\n",
        "def calculate_gain(original_loss,feature,g,h,threshold,reg_lambda):\n",
        "  '''\n",
        "  Given the original loss,\n",
        "  and the threshold to split,\n",
        "  calcualte the new loss.\n",
        "  '''\n",
        "  left_g=0\n",
        "  left_h=0\n",
        "  right_g=0\n",
        "  right_h=0\n",
        "  for i in range(len(feature)):\n",
        "    if feature[i]<threshold:\n",
        "      left_g+=g[i]\n",
        "      left_h+=h[i]\n",
        "    else:\n",
        "      right_g+=g[i]\n",
        "      right_h+=h[i]\n",
        "  \n",
        "  left_loss = -0.5*np.square(left_g)/(left_h+reg_lambda)\n",
        "  right_loss = -0.5*np.square(right_g)/(right_h+reg_lambda)\n",
        "  return original_loss - left_loss - right_loss\n",
        "\n",
        "@jit\n",
        "def find_threshold(g,h,train,reg_lambda):\n",
        "  '''\n",
        "  Given a particular feature,\n",
        "  return the best split threshold together with the gain that is achieved.\n",
        "  '''\n",
        "  loss = leaf_loss(g,h,reg_lambda)\n",
        "  threshold=None\n",
        "  best_gain=0\n",
        "  unq = np.unique(train)\n",
        "  for i in range(1,len(unq)):\n",
        "    this_threshold=(unq[i-1] + unq[i])/2\n",
        "    this_gain=calculate_gain(loss,train,g,h,this_threshold,reg_lambda)\n",
        "    if this_gain>best_gain:\n",
        "      best_gain=this_gain\n",
        "      threshold=this_threshold\n",
        "  \n",
        "  return threshold,best_gain\n",
        "\n",
        "@jit\n",
        "def find_best_split(train,g,h,reg_lambda):\n",
        "  '''\n",
        "  Return the best feature to split together with the corresponding threshold.\n",
        "  Each feature is scanned by find_threshold(),\n",
        "  a (threshold,gain) tuple is returned for each feature.\n",
        "  Then we select the feature with the largest best_gain,\n",
        "  and return index of that feature, the threshold, and the gain that is achieved.\n",
        "  '''\n",
        "  train=train.T \n",
        "  feature=0\n",
        "  threshold=None\n",
        "  best_gain=0\n",
        "  for i in range(len(train)):\n",
        "    this_threshold,this_gain=find_threshold(g,h,train[i],reg_lambda) # 获取第 i 个特征的threshold 和 gain\n",
        "    if this_gain>best_gain:\n",
        "      feature=i\n",
        "      threshold=this_threshold\n",
        "      best_gain=this_gain\n",
        "  return feature,threshold,best_gain\n",
        "\n",
        "\n",
        "class loss(metaclass=ABCMeta):\n",
        "  '''\n",
        "  The abstract base class for loss function.\n",
        "  Three things should be specified for a loss,\n",
        "  namely link function, gradient and hessian.\n",
        "  link() is the link function, which takes scores as input, and returns predictions.\n",
        "  g() is the gradient,which takes true values and scores as input, and returns gradient.\n",
        "  h() is the hessian,which takes true values and scores as input, and hessian.\n",
        "  All inputs and outputs are numpy arrays.\n",
        "  '''\n",
        "  @abstractmethod\n",
        "  def link(self,score):\n",
        "    pass\n",
        "  \n",
        "  @abstractmethod\n",
        "  def g(self,true,score):\n",
        "    pass\n",
        "  \n",
        "  @abstractmethod\n",
        "  def h(self,true,score):\n",
        "    pass\n",
        "  \n",
        "class mse(loss):\n",
        "  '''Loss class for mse. As for mse,link function is pred=score.'''\n",
        "  def link(self,score):\n",
        "    return score\n",
        "  \n",
        "  def g(self,true,score):\n",
        "    return score-true\n",
        "  \n",
        "  def h(self,true,score):\n",
        "    return np.ones_like(score)\n",
        "  \n",
        "class log(loss):\n",
        "  '''Loss class for log loss. As for log loss,link function is logistic transformation.'''\n",
        "  def link(self,score):\n",
        "    return 1/(1+np.exp(-score))\n",
        "  \n",
        "  def g(self,true,score):\n",
        "    pred=self.link(score)\n",
        "    return pred-true\n",
        "  \n",
        "  def h(self,true,score):\n",
        "    pred=self.link(score)\n",
        "    return pred*(1-pred)\n",
        "  \n",
        "\n",
        "class GBDT(object):\n",
        "  '''\n",
        "  Parameters:\n",
        "  ----------\n",
        "  n_threads: The number of threads used for fitting and predicting.\n",
        "  loss: Loss function for  gradient boosting.\n",
        "    'mse' for reegression task and 'log' for classification task.\n",
        "    A child class of the loss class could be passed to implement customized loss.\n",
        "  max_depth: The maximum depth of a tree.\n",
        "  min_sample_split: The minimum number of samples required to further split a node.\n",
        "  reg_lambda:  The regularization coefficient for leaf score, also known as lambda.\n",
        "  gamma: The regulartion coefficient for number of tree nodes, also known as gamma.\n",
        "  learning_rate: The learning rate of gradient boosting.\n",
        "  n_estimators: Number  of trees.\n",
        "  '''\n",
        "  def __init__(self,\n",
        "               loss='mse',\n",
        "               max_depth=3,min_sample_split=10,reg_lambda=1,gamma=0,\n",
        "               learning_rate=0.1,n_estimators=100):\n",
        "    self.loss=loss\n",
        "    self.max_depth=max_depth\n",
        "    self.min_sample_split=min_sample_split\n",
        "    self.reg_lambda=reg_lambda\n",
        "    self.gamma=gamma\n",
        "    self.learning_rate=learning_rate\n",
        "    self.n_estimators=n_estimators\n",
        "  \n",
        "  def fit(self,train,target):\n",
        "    self.estimators=[]\n",
        "    if self.loss=='mse':\n",
        "      self.loss=mse()\n",
        "    if self.loss=='log':\n",
        "      self.loss=log()\n",
        "    self.score_start=target.mean()\n",
        "    score=np.ones(len(train))*self.score_start\n",
        "    for i in range(self.n_estimators):\n",
        "      estimator=Tree(\n",
        "          max_depth=self.max_depth,\n",
        "          min_sample_split=self.min_sample_split,\n",
        "          reg_lambda=self.reg_lambda,\n",
        "          gamma=self.gamma\n",
        "      )\n",
        "      estimator.fit(train,g=self.loss.g(target,score),h=self.loss.h(target,score))\n",
        "      self.estimators.append(estimator)\n",
        "      score+=self.learning_rate*estimator.predict(train)\n",
        "    return self\n",
        "  \n",
        "  def predict(self,test):\n",
        "    score=np.ones(len(test))*self.score_start\n",
        "    for i in range(self.n_estimators):\n",
        "      score+=self.learning_rate*self.estimators[i].predict(test)\n",
        "    return self.loss.link(score)\n",
        "\n",
        "\n",
        "class TreeNode(object):\n",
        "  '''\n",
        "  The data structure that are used for storing trees.\n",
        "  A tree is presented by a set of nested TreeNodes,\n",
        "  with one TreeNode pointing two child TreeNodes,\n",
        "  until a tree leaf is reached.\n",
        "\n",
        "  Parameters:\n",
        "  ----------\n",
        "  is_leaf: If is TreeNode is a leaf.\n",
        "  score: The prediction (score) of a tree leaf.\n",
        "  split_feature: The split feature feature of a tree node.\n",
        "  split_threshold: The split threshold of a tree node.\n",
        "  left_child: Pointing to a child TreeNode,\n",
        "    where the value of split feature is less than the split threshold.\n",
        "  right_child: Pointing to a child TreeNode,\n",
        "    where the value of split feature is greater than or equal to the split threshold.\n",
        "  '''\n",
        "  def __init__(self,\n",
        "               is_leaf=False,score=None,\n",
        "               split_feature=None,split_threshold=None,\n",
        "               left_child=None,right_child=None):\n",
        "    self.is_leaf=is_leaf\n",
        "    self.score=score\n",
        "    self.split_feature=split_feature\n",
        "    self.split_threshold=split_threshold\n",
        "    self.left_child=left_child\n",
        "    self.right_child=right_child\n",
        "\n",
        "\n",
        "class Tree(object):\n",
        "  '''\n",
        "  This is the building block for GBDT,\n",
        "  which is a single decision tree,\n",
        "  also known as an estimator.\n",
        "\n",
        "  Parameters:\n",
        "  -----------\n",
        "  n_threads: The number of threads used for fitting and predicting.\n",
        "  max_depth: The maximum depth of the tree.\n",
        "  min_sample_split: The minimum number of samples required to further split a node.\n",
        "  reg_lambda: The regularization coefficient for leaf prediction,also known as lambda.\n",
        "  gamma: The regularization coefficient for number of TreeNode, also known as gamma.\n",
        "  '''\n",
        "  def __init__(self,max_depth=3,min_sample_split=10,reg_lambda=1,gamma=0):\n",
        "    self.max_depth=max_depth\n",
        "    self.min_sample_split=min_sample_split\n",
        "    self.reg_lambda=reg_lambda\n",
        "    self.gamma=gamma\n",
        "  \n",
        "  def fit(self,train,g,h):\n",
        "    '''\n",
        "    All inputs must be numpy arrays.\n",
        "    g and h are gradient and hessian respectively.\n",
        "    '''\n",
        "    self.estimator=self.construct_tree(train,g,h,self.max_depth)\n",
        "    return self\n",
        "  \n",
        "  def predict(self,test):\n",
        "    '''\n",
        "    test must by numpy array.\n",
        "    Return predictions (scores) as an array.\n",
        "    Multiprocssing is supported for prediction.\n",
        "    '''\n",
        "    result=np.zeros(len(test))\n",
        "    for i in  range(len(test)):\n",
        "      result[i]=self.predict_single(self.estimator,test[i])\n",
        "    return result\n",
        "  \n",
        "  def predict_single(self,treenode,test):\n",
        "    '''\n",
        "    The predict method for a single sample point.\n",
        "    test must be numpy array.\n",
        "    Return prediction (score) as a number.\n",
        "    '''\n",
        "    if treenode.is_leaf:\n",
        "      return treenode.score\n",
        "    else:\n",
        "      if test[treenode.split_feature]<treenode.split_threshold:\n",
        "        return self.predict_single(treenode.left_child,test)\n",
        "      else:\n",
        "        return self.predict_single(treenode.right_child,test)\n",
        "  \n",
        "  def construct_tree(self,train,g,h,max_depth):\n",
        "    '''\n",
        "    Construct tree recursively.\n",
        "    First we should check if we should stop further splitting.\n",
        "    The stop conditions include:\n",
        "    1. We have reached the pre-determined max_depth\n",
        "    2. The number of sample points at this node is less than min_sample_split\n",
        "    3. The best gain is less than gamma.\n",
        "    4. Targets take only one value.\n",
        "    5. Each feature takes only on value.\n",
        "    By carefull design, we could avoid checking condition 4 and 5 explicitly.\n",
        "    In function find_threshold(), the best_gain is set to 0 initially.\n",
        "    So if there are no further feature split,\n",
        "    or all the targets take same value,\n",
        "    the return value of best_gain would be zero.\n",
        "    Thus condition 3 would be satisfied,\n",
        "    and no further splitting would be done.\n",
        "    To conclude, we need only to check condition 1,2 and 3.\n",
        "    '''\n",
        "    if max_depth==0 or len(train)<self.min_sample_split:\n",
        "      return TreeNode(is_leaf=True,score=leaf_score(g,h,self.reg_gamma))\n",
        "    \n",
        "    feature,threshold,gain=find_best_split(train,g,h,self.reg_lambda)\n",
        "\n",
        "    if gain<=self.gamma:\n",
        "      return TreeNode(is_leaf=True,score=leaf_score(g,h,self.reg_lambda))\n",
        "    \n",
        "    index=train[:,feature]<threshold\n",
        "    left_child=self.construct_tree(train[index],g[index],h[index],max_depth-1)\n",
        "    right_child=self.construct_tree(train[~index],g[~index],h[~index],max_depth-1)\n",
        "    return TreeNode(split_feature=feature,split_threshold=threshold,left_child=left_child,right_child=right_child)\n",
        "  \n"
      ],
      "metadata": {
        "id": "OcYLE22LmK4D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8tOFHhbGlToZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "x = np.empty([3,2], dtype = int) \n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtR2spMelT8W",
        "outputId": "9423e983-40fe-434f-cd59-4da9ac9b03fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[50902800        0]\n",
            " [       0        0]\n",
            " [       0        0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_unq=np.unique(x)\n",
        "print(x_unq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqd6rXN3lb7A",
        "outputId": "5ef88d4a-0dbf-440f-c942-3e60311e9d33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[       0 41704624]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_unq[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHWJs_G4lr-6",
        "outputId": "647c86d6-0330-4bd8-bc85-80015c202611"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41704624"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGpHX8q0l01s",
        "outputId": "c710a7c0-fc04-4f0d-f634-9cb77703abcc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[50902800,        0,        0],\n",
              "       [       0,        0,        0]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.T[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGmKjuxSodU3",
        "outputId": "c36a2b3c-2d76-4f3d-eb75-fb83d99df948"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.T[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ynedzkvoj2r",
        "outputId": "18faddd5-febe-48a8-b77f-e8414ce633f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([50902800,        0,        0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ReqoHn4RolHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}